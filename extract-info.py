from pymongo import MongoClient
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_community.document_loaders import DirectoryLoader
from langchain.chains import RetrievalQA
import gradio as gr
from gradio.themes.base import Base
import key_param
from langchain_community.vectorstores import MongoDBAtlasVectorSearch
from langchain_community.llms import OpenAI

client = MongoClient(key_param.MONGO_URI)
dbName = "langchain"
collectionName = "collection of text blobs"
collection = client[dbName][collectionName]



embeddings = OpenAIEmbeddings(openai_api_key=key_param.open_api_key)


vectorStore = MongoDBAtlasVectorSearch( collection, embeddings )

def query_data(query):
    docs = vectorStore.similarity_search(query, k = 1)
    as_output = docs[0].page_content

    llm = OpenAI(openai_api_key=key_param.open_api_key, temperature=0)

    retreiver = vectorStore.as_retriever()
    qa = RetrievalQA.from_chain_type(llm, chain_type="stuff", retriever=retreiver)
    retreiver_output = qa.run(query)  # Adjust temperature as needed

    return as_output, retreiver_output

with gr.Blocks(theme=Base(), title="Question Answering App using vector search + RAG " ) as demo:
    gr.Markdown(
        """
           # Question answering App using Atlas Vector search + RAG Archtecture 
        """)
    textbox = gr.Textbox(label="Enter your Question:" )
    with gr.Row():
        button = gr.Button("Submit", variant = "primary" )
    with gr.Column():
        output1 = gr.Textbox(lines = 1, max_lines = 10, label= "output with just Atlas Vector Search (returns text field as is):")
        output2 = gr.Textbox(lines = 1, max_lines = 10, label= "output generated by cahining Atlas Vector Search to Langchain's RetrieverQA + OpenAI LLM: " )
        
    button.click(query_data,textbox, outputs = [output1,output2])

demo.launch()